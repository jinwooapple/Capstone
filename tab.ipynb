{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"mbn-xxFjmIl8"},"outputs":[],"source":["!pip install ace_tools_open\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"SRDE8iVdhOEi"},"outputs":[],"source":["!pip list\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"DKaQ4H8lC_Xa"},"outputs":[],"source":["!pip install pytorch_tabnet"]},{"cell_type":"code","source":["!pip install torch==2.5.1"],"metadata":{"id":"bMsDOxQ_pCIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JiOfsVNgkhE8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n","from itertools import product\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from pytorch_tabnet.pretraining import TabNetPretrainer\n","import torch\n","\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"/content/drive/MyDrive/train_val.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n","\n","# features =  ['away_prob_5', 'HTAG_5', 'B365H', 'PSH', 'HSRA', 'ASRA']\n","# features =  ['B365H', 'PSH', 'HSRA', 'ASRA']\n","# features =  ['away_prob_5', 'HTAG_5', 'B365H', 'HSRA', 'ASRA']\n","features =  ['home_prob_5','away_prob_5', 'xg_home_5','xg_away_5',  'HTHG_5', 'HTAG_5', 'HST_5','AST_5',\n","             'elo_home','elo_away','home_advantage','HPA','APA','HSA','ASA', 'B365H', 'B365D', 'B365A','PSH', 'PSD', 'PSA','HSRA', 'ASRA'] #전체 변수\n","# features =  ['away_prob_5', 'elo_home', 'HSA', 'B365H', 'PSD', 'B365D']\n","\n","target = 'result'\n","\n","X = data[features].values # train data\n","y = data[target].replace({'home':0,'away':1,'draw':2}).values\n","\n","X_t = test[features].values #test data\n","y_t = test[target].replace({'home':0,'away':1,'draw':2}).values\n","\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","# TabNet 하이퍼파라미터 후보\n","n_d_list = [4] #4\n","n_a_list = [4] #4\n","n_steps_list = [2]#2\n","gamma_list = [0.9] #0.9\n","lr_list = [0.04] #0.04\n","batch_size_list = [32] #32\n","\n","results = []\n","\n","# 가능한 모든 조합\n","param_combinations = list(product(n_d_list, n_a_list, n_steps_list, gamma_list, lr_list, batch_size_list))\n","\n","for n_d, n_a, n_steps, gamma, lr, batch_size in param_combinations:\n","    try:\n","        #pretrain\n","        pretrainer = TabNetPretrainer(\n","            n_d=n_d,\n","            n_a=n_a,\n","            n_steps=n_steps,\n","            gamma=gamma,\n","            mask_type='sparsemax',\n","            optimizer_params={'lr': lr},\n","            verbose=0,\n","            seed=42\n","        )\n","\n","        pretrainer.fit(\n","            X_train=X,\n","            eval_set=[X],\n","            max_epochs=100,\n","            batch_size=batch_size,\n","            virtual_batch_size=16,\n","            patience=10,\n","            num_workers=0,\n","            drop_last=False\n","        )\n","\n","        acc_scores = []\n","        bal_acc_scores = []\n","        f1_scores = []\n","\n","        for train_idx, test_idx in kf.split(X, y):\n","            X_train, X_test = X[train_idx], X[test_idx]\n","            y_train, y_test = y[train_idx], y[test_idx]\n","\n","            model = TabNetClassifier(\n","              n_d=n_d,\n","              n_a=n_a,\n","              n_steps=n_steps,\n","              gamma=gamma,\n","              #optimizer_fn=None,\n","              optimizer_params={\"lr\": lr},\n","              mask_type='sparsemax',\n","              # scheduler_params={\"step_size\":20, \"gamma\":0.9},\n","              # scheduler_fn=torch.optim.lr_scheduler.StepLR,\n","              verbose=0,\n","              seed=42\n","          )\n","            # 학습\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_test, y_test)],\n","                eval_name=['valid'],\n","                eval_metric=['accuracy'],\n","                max_epochs=100,\n","                patience=10,\n","                batch_size=batch_size,\n","                virtual_batch_size=16,\n","                num_workers=0,\n","                drop_last=False,\n","                from_unsupervised=pretrainer #pretrain load\n","            )\n","\n","            # 예측\n","            model.network.eval()\n","            y_pred = model.predict(X_test)\n","\n","            acc_scores.append(accuracy_score(y_test, y_pred))\n","            bal_acc_scores.append(balanced_accuracy_score(y_test, y_pred))\n","            f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n","\n","        # 교차검증 평균\n","        avg_acc = np.mean(acc_scores)\n","        avg_bal = np.mean(bal_acc_scores)\n","        avg_f1 = np.mean(f1_scores)\n","\n","        model_t = TabNetClassifier(\n","              n_d=n_d,\n","              n_a=n_a,\n","              n_steps=n_steps,\n","              gamma=gamma,\n","              #optimizer_fn=None,\n","              optimizer_params={\"lr\": lr},\n","              mask_type='sparsemax',\n","              # scheduler_params={\"step_size\":20, \"gamma\":0.9},\n","              # scheduler_fn=torch.optim.lr_scheduler.StepLR,\n","              verbose=0,\n","              seed=42\n","        )\n","\n","\n","        # 전체 데이터 학습\n","        model_t.fit(\n","            X, y,\n","            max_epochs=100,\n","            patience=10,\n","            batch_size=batch_size,\n","            virtual_batch_size=16,\n","            num_workers=0,\n","            drop_last=False,\n","            from_unsupervised=pretrainer  #pretrain load\n","        )\n","\n","        # 테스트 예측\n","        model_t.network.eval()\n","        y_pred_t = model_t.predict(X_t)\n","\n","        acc_t = accuracy_score(y_t, y_pred_t)\n","        bal_t = balanced_accuracy_score(y_t, y_pred_t)\n","        f1_t = f1_score(y_t, y_pred_t, average='weighted')\n","\n","        results.append((n_d, n_a, n_steps, gamma, lr, batch_size, avg_acc, avg_bal, avg_f1, acc_t, bal_t, f1_t))\n","\n","    except Exception as e:\n","        print(f\"Error with params {n_d, n_a, n_steps, gamma, lr, batch_size} due to {e}\")\n","\n","# 결과 데이터프레임\n","results_df = pd.DataFrame(\n","    results,\n","    columns=['n_d','n_a','n_steps','gamma','lr','batch_size',\n","             'avg_acc','avg_bal','avg_f1','acc_t','bal_t','f1_t']\n",")\n","\n","# 정렬\n","results_df = results_df.sort_values(by='acc_t', ascending=False)\n","\n","# 출력\n","import ace_tools_open as tools\n","tools.display_dataframe_to_user(name='TabNet Hyperparameter Tuning Results', dataframe=results_df)\n","\n","# 튜닝 해서 최적 파라미터 찾은 후에 주석 해제-> 변수 중요도 출력\n","# feature_importance = pd.DataFrame({\n","#     \"feature\": features,\n","#     \"importance\": model_t.feature_importances_\n","# }).sort_values(by=\"importance\", ascending=False)\n","\n","# print(feature_importance)\n","\n","# clf: TabNetClassifier 학습 완료 상태\n","# torch.save(model_t.network.state_dict(), \"/content/drive/MyDrive/tabnet_model_5759.pth\")"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1vY2aRdYjNyMFKytqUBEBrwX1wqGseL_N","authorship_tag":"ABX9TyOrNQVsc+DcaMfURMynrmY0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}